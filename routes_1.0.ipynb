{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización de rutas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importar librerias necesarias\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from geopy.distance import great_circle\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import linkage ,fcluster\n",
    "import googlemaps\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\martin.olivares\\Desktop\\projects\\best-route\\data\\test_minutos.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de valores erroneos:\n",
      "address            0\n",
      "hora_recogida      0\n",
      "destino            0\n",
      "nombre_pasajero    0\n",
      "mail               0\n",
      "phone              0\n",
      "fecha              0\n",
      "num_empty_cells    0\n",
      "nulls              7\n",
      "datetime_1         0\n",
      "dtype: int64\n",
      "-----------------------------------\n",
      "Lista errores:\n"
     ]
    }
   ],
   "source": [
    "#limpiar data\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df['address']=data['Direccion de inicio']\n",
    "df['hora_recogida']=data['Hora de recogida']\n",
    "df['destino']=data['Dirección destino']\n",
    "df['nombre_pasajero']=data['Nombre de pasajero']                     #nueva\n",
    "df['mail']=data['Correo pasajero']                                  #nueva\n",
    "df['phone']=data['Telefono de contacto']#.apply(lambda x: round(x))\n",
    "df['fecha']=data['fecha']\n",
    "\n",
    "df[\"num_empty_cells\"] = df.isna().sum(axis=1)\n",
    "df[\"nulls\"]=df['num_empty_cells']/max(df['num_empty_cells'])\n",
    "\n",
    "\n",
    "# Función para crear objetos datetime\n",
    "def crear_datetime(row):\n",
    "    fecha_str = row['fecha']\n",
    "    hora_str = row['hora_recogida']\n",
    "    # Convertir la cadena de texto de hora a un objeto time\n",
    "    hora = datetime.strptime(hora_str, '%H:%M').time()\n",
    "    # Crear un objeto datetime a partir de la fecha y hora\n",
    "    fecha = datetime.strptime(fecha_str, '%Y-%m-%d').date()\n",
    "    fecha_y_hora = datetime.combine(fecha, hora)\n",
    "    return fecha_y_hora\n",
    "\n",
    "# Agregar una nueva columna datetime y conservar las columnas existentes\n",
    "df = df.assign(datetime_1=df.apply(crear_datetime, axis=1))\n",
    "\n",
    "\n",
    "\n",
    "print('Numero de valores erroneos:')\n",
    "print(df.isna().sum())\n",
    "print('-----------------------------------')\n",
    "print('Lista errores:')\n",
    "#df[df.isna().any(axis=1)]\n",
    "\n",
    "df = df.drop(df[df['nulls']==1].index)\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "\n",
    "df.drop(columns=['nulls','num_empty_cells'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corregir typos\n",
    "# Definir un diccionario con las abreviaturas de calles y sus correspondientes formas completas\n",
    "street_abbreviations = {\n",
    "    \"cl\": \"calle\",\n",
    "    \"av\": \"avenida\",\n",
    "    \"pj\": \"pasaje\",\n",
    "    \"cam\": \"camino\",\n",
    "    \"nte\": \"norte\",\n",
    "    \"hermnos\":'hnos',\n",
    "    'hmnos':'hermanos',\n",
    "    'tte':'teniente',\n",
    "    'concon':'con con'\n",
    "    }\n",
    "\n",
    "\n",
    "# Definir una función que corrija las abreviaturas de calles en una dirección\n",
    "def correct_typos(address):\n",
    "    for abbreviation, full_form in street_abbreviations.items():\n",
    "        address = re.sub(r'\\b{}\\b'.format(abbreviation), full_form, address)\n",
    "    return address\n",
    "\n",
    "# Aplicar la función a cada dirección del DataFrame\n",
    "df[\"address\"] = df[\"address\"].str.lower().apply(correct_typos)\n",
    "df['destino'] = df[\"destino\"].str.lower().apply(correct_typos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crear funciones de caché y de limpieza de direcciones\n",
    "\n",
    "clave_api='AIzaSyAvTzCycvOetN-NA51GNqxb80d-Ma-0Azg'\n",
    "\n",
    "googlemaps_cache = 'googlemaps_cache.pkl'\n",
    "\n",
    "def load_cache():\n",
    "    # Cargar la caché desde el archivo si existe\n",
    "    if os.path.exists(googlemaps_cache):\n",
    "        with open(googlemaps_cache, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "def save_cache(cache):\n",
    "    # Guardar la caché en el archivo\n",
    "    with open(googlemaps_cache, 'wb') as f:\n",
    "        pickle.dump(cache, f)\n",
    "\n",
    "def correct_address(direccion):\n",
    "    # Cargar la caché desde el archivo\n",
    "    cache = load_cache()\n",
    "    # Verificar si el resultado de la dirección ya está en la caché\n",
    "    if direccion in cache:\n",
    "        return cache[direccion]\n",
    "    # Si el resultado de la dirección no está en la caché, realizar una solicitud a la API de Google Maps\n",
    "    gmaps = googlemaps.Client(key=clave_api)\n",
    "    geocode_result = gmaps.geocode(direccion)\n",
    "    if len(geocode_result) > 0:\n",
    "        formatted_address = geocode_result[0]['formatted_address']\n",
    "        # Agregar el resultado a la caché para futuras solicitudes\n",
    "        cache[direccion] = formatted_address\n",
    "        save_cache(cache)\n",
    "        return formatted_address\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def reverse_geocode(lat, lon):\n",
    "    # Hacer reverse geocoding para obtener la dirección correspondiente\n",
    "    reverse_geocode_result = gmaps.reverse_geocode((lat, lon))\n",
    "    # Obtener la dirección formateada del primer resultado\n",
    "    formatted_address = reverse_geocode_result[0]['formatted_address']\n",
    "    # Devolver la dirección formateada como una cadena\n",
    "    return formatted_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corregir direcciones y saber si hay valores erroneos\n",
    "\n",
    "df['address'] = df['address'].apply(correct_address)\n",
    "df['destino'] = df['destino'].apply(correct_address)\n",
    "\n",
    "df['aux'] = ~(df.groupby(['destino', 'datetime_1'])['address'].transform('nunique') > 1)\n",
    "\n",
    "#df['aux'] = df.groupby(['address', 'hora_recogida'])['address'].transform(lambda x: x.duplicated(keep=False)).astype(bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear funciones de georeferenciación y caché\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Creamos un cliente de Google Maps con nuestra clave API\n",
    "gmaps = googlemaps.Client(key=clave_api)\n",
    "\n",
    "# Comprobamos si el archivo existe y no está vacío antes de cargar la memoria caché\n",
    "if os.path.exists(\"coordinates_googlemaps.pkl\") and os.path.getsize(\"geocode_cache.pickle\") > 0:\n",
    "    with open(\"coordinates_googlemaps.pkl\", \"rb\") as f:\n",
    "        geocode_cache = pickle.load(f)\n",
    "else:\n",
    "    geocode_cache = {}\n",
    "\n",
    "# Creamos una función para guardar la memoria caché en un archivo externo\n",
    "def save_geocode_cache():\n",
    "    with open(\"coordinates_googlemaps.pkl\", \"wb\") as f:\n",
    "        pickle.dump(geocode_cache, f)\n",
    "\n",
    "# Creamos una función para geolocalizar una dirección y almacenar las coordenadas en la caché\n",
    "def geolocate(address):\n",
    "    if address in geocode_cache:\n",
    "        return geocode_cache[address]\n",
    "    else:\n",
    "        geocode_result = gmaps.geocode(address)\n",
    "        if len(geocode_result) > 0:\n",
    "            location = geocode_result[0]['geometry']['location']\n",
    "            coordinates = (location['lat'], location['lng'])\n",
    "            geocode_cache[address] = coordinates\n",
    "            save_geocode_cache()  # Guardamos la memoria caché en un archivo externo\n",
    "            return coordinates\n",
    "        else:\n",
    "            return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separar por muchos origenes un destino, muchos destinos un origen y un origen un destino\n",
    "df.sort_values(by=['datetime_1'],inplace=True)\n",
    "df['id'] = range(len(df))\n",
    "\n",
    "false_df = df[df['aux']==False]\n",
    "true_df = df[df['aux']==True]\n",
    "\n",
    "#print(len(true_df))\n",
    "\n",
    "#ahora se obtiene cuando existen un origen un destino\n",
    "# 1. marcar con un flag y sacarlas del calculo de distancias\n",
    "# 2. contar la cantidad de personas y definir el producto\n",
    "\n",
    "#true_df['aux1'] = true_df.duplicated(subset=['hora_recogida', 'address','destino','fecha'], keep=False)\n",
    "#same_origin=true_df[true_df['aux1']==True]\n",
    "#true_df=true_df[true_df['aux1']==False]\n",
    "\n",
    "#print(len(true_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paso 1.1.1 (distintos origenes -> un destino; crear clusters)\n",
    "\n",
    "false_df['label'] = np.nan\n",
    "\n",
    "# Agrega una nueva columna con la fecha y hora de recogida combinadas\n",
    "false_df['datetime'] = false_df['fecha'] + ' ' + false_df['hora_recogida']\n",
    "\n",
    "# Agrupa por fecha y hora de recogida combinadas, y por hora de recogida\n",
    "datetime_grouped = false_df.groupby('datetime')\n",
    "\n",
    "# Recorre cada grupo y aplica clustering\n",
    "for name, group in datetime_grouped:\n",
    "    # Calcula la distancia entre cada par de direcciones\n",
    "    X = np.zeros((len(group), len(group)))\n",
    "    for i in range(len(group)):\n",
    "        address1 = group.iloc[i]['address']\n",
    "        loc1 = geolocate(address1) # Utilizamos nuestra función personalizada para geolocalizar la dirección\n",
    "        if loc1 is not None:\n",
    "            lat1, lon1 = loc1\n",
    "            point1 = (lat1, lon1)\n",
    "            for j in range(i+1, len(group)):\n",
    "                address2 = group.iloc[j]['address']\n",
    "                loc2 = geolocate(address2) # Utilizamos nuestra función personalizada para geolocalizar la dirección\n",
    "                if loc2 is not None:\n",
    "                    lat2, lon2 = loc2\n",
    "                    point2 = (lat2, lon2)\n",
    "                    X[i, j] = great_circle(point1, point2).m\n",
    "                    X[j, i] = great_circle(point1, point2).m\n",
    "                    \n",
    "    # Crea una matriz con las distancias\n",
    "        kmeans = KMeans(n_clusters=1)\n",
    "        kmeans.fit(X)\n",
    "        group['label'] = kmeans.labels_\n",
    "        labels = np.zeros(len(group))\n",
    "        \n",
    "        # Asigna un número de cluster único a cada grupo\n",
    "        last_label = false_df['label'].max()\n",
    "        if np.isnan(last_label):\n",
    "            cluster_label = 1\n",
    "        else:\n",
    "            cluster_label = last_label + 1\n",
    "        for i in range(len(group)):\n",
    "            if labels[i] == 0:\n",
    "                labels[i] = cluster_label\n",
    "                for j in range(i+1, len(group)):\n",
    "                    if labels[j] == 0 and np.sum(labels == cluster_label) < 8 and X[i, j] > 0:\n",
    "                        labels[j] = cluster_label\n",
    "                if np.sum(labels == cluster_label) > 0:\n",
    "                    cluster_label += 1\n",
    "    \n",
    "    # Asigna las etiquetas de los clusters al dataframe original\n",
    "    group['label'] = labels\n",
    "    false_df.loc[group.index, \"label\"] = group[\"label\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#paso 1.1.1 (distintos origenes -> un destino; crear clusters)\n",
    "\n",
    "#primero agrpar por fecha y despues VOVLER  agrupar con hora_recogida\n",
    "\n",
    "\n",
    "\n",
    "for name, group in false_grouped:\n",
    "    # Calcula la distancia entre cada par de direcciones\n",
    "    X = np.zeros((len(group), len(group)))\n",
    "    for i in range(len(group)):\n",
    "        address1 = group.iloc[i]['address']\n",
    "        loc1 = geolocate(address1)  # Utilizamos nuestra función personalizada para geolocalizar la dirección\n",
    "        if loc1 is not None:\n",
    "            lat1, lon1 = loc1\n",
    "            point1 = (lat1, lon1)\n",
    "            for j in range(i+1, len(group)):\n",
    "                address2 = group.iloc[j]['address']\n",
    "                loc2 = geolocate(address2)  # Utilizamos nuestra función personalizada para geolocalizar la dirección\n",
    "                if loc2 is not None:\n",
    "                    lat2, lon2 = loc2\n",
    "                    point2 = (lat2, lon2)\n",
    "                    X[i, j] = great_circle(point1, point2).m\n",
    "                    X[j, i] = great_circle(point1, point2).m\n",
    "    # Crea una matriz con las distancias\n",
    "    kmeans = KMeans(n_clusters=1)\n",
    "    kmeans.fit(X)\n",
    "    group['label'] = kmeans.labels_\n",
    "    labels = np.zeros(len(group))\n",
    "    cluster_label = 1\n",
    "    for i in range(len(group)):\n",
    "        if labels[i] == 0:\n",
    "            labels[i] = cluster_label\n",
    "            for j in range(i+1, len(group)):\n",
    "                if labels[j] == 0 and np.sum(labels == cluster_label) < 8 and X[i, j] > 0:\n",
    "                    labels[j] = cluster_label\n",
    "            cluster_label += 1\n",
    "            \n",
    "    group['label'] = labels\n",
    "    false_df.loc[group.index, \"label\"] = group[\"label\"]\n",
    "\n",
    "false_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paso 1.1.2 (distintos origenes -> un destino; agregar destino de la ruta)\n",
    "\n",
    "false_df=false_df[['hora_recogida','address','destino','label','id','nombre_pasajero','mail','phone','datetime_1']] #######\n",
    "false_df=false_df.sort_values(by=['label'])\n",
    "\n",
    "grouped= false_df.groupby(['destino','label'])\n",
    "\n",
    "for data,group in grouped:\n",
    "    group.reset_index(drop=True,inplace=True)\n",
    "    nueva_fila = {'hora_recogida': group['hora_recogida'][0], 'address': data[0], 'destino': data[0],'label': data[1]}\n",
    "    false_df = false_df.append(nueva_fila, ignore_index=True)\n",
    "    \n",
    "false_df['aux']= false_df['address']==false_df['destino']\n",
    "\n",
    "false_df=false_df.sort_values(by=['label']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paso 1.1.3 (distintos origenes -> un destino; calcular la ruta más eficiente)\n",
    "\n",
    "\n",
    "clave_api='AIzaSyAvTzCycvOetN-NA51GNqxb80d-Ma-0Azg'\n",
    "\n",
    "# Agregar columnas para latitud y longitud\n",
    "false_df['latitud'] = None\n",
    "false_df['longitud'] = None\n",
    "\n",
    "# Iterar por cada dirección y obtener las coordenadas\n",
    "for index, row in false_df.iterrows():\n",
    "    direccion = row['address']\n",
    "    resultado = gmaps.geocode(direccion)\n",
    "    latitud = resultado[0]['geometry']['location']['lat']\n",
    "    longitud = resultado[0]['geometry']['location']['lng']\n",
    "    false_df.at[index, 'latitud'] = latitud\n",
    "    false_df.at[index, 'longitud'] = longitud\n",
    "    \n",
    "# Crear una lista vacía para almacenar los dataframes con los órdenes de las ubicaciones\n",
    "orden_dfs = []\n",
    "##------------------------------------------------------------------------- bien hasta acá\n",
    "# Agrupar el dataframe por cluster\n",
    "grupos = false_df.groupby('label')\n",
    "\n",
    "# Iterar por cada cluster\n",
    "\n",
    "for grupo, data in grupos:\n",
    "    gmaps = googlemaps.Client(key='AIzaSyBDGJCBvgh1BsTLpiDf1UVAwU9e9b_lrd8')\n",
    "    data = data.reset_index(drop=True)\n",
    "    ubicaciones = list(zip(data['latitud'], data['longitud']))\n",
    "    \n",
    "    # Definir el primer destino como el origen\n",
    "    primer_destino_idx = data.loc[data['aux'] == True].iloc[-1].name\n",
    "    primer_destino_id = data.loc[data['aux'] == True, 'id'].iloc[-1]\n",
    "    ruta_optima = [(primer_destino_idx, primer_destino_id)]\n",
    "    \n",
    "    # Iterar hasta que se hayan agregado todos los destinos a la ruta\n",
    "    while len(ruta_optima) < len(data):\n",
    "        # Obtener la ubicación actual y las ubicaciones restantes\n",
    "        ubicacion_actual_idx, ubicacion_actual_id = ruta_optima[-1]\n",
    "        ubicacion_actual = ubicaciones[ubicacion_actual_idx]\n",
    "        ubicaciones_restantes = [(i, id_) for i, id_ in zip(range(len(ubicaciones)), data['id']) if i not in [idx for idx, _ in ruta_optima]]\n",
    "        # Calcular la distancia de la ubicación actual a cada ubicación restante\n",
    "        distances = gmaps.distance_matrix(ubicacion_actual, [ubicaciones[i] for i, _ in ubicaciones_restantes], mode='driving')\n",
    "        distances = distances['rows'][0]['elements']\n",
    "        # Ordenar las ubicaciones restantes por distancia al siguiente destino\n",
    "        sorted_indices = sorted(range(len(distances)), key=lambda k: distances[k]['distance']['value'])\n",
    "        # Elegir el siguiente destino como la ubicación más cercana\n",
    "        siguiente_destino_idx, siguiente_destino_id = ubicaciones_restantes[sorted_indices[0]]\n",
    "        # Agregar el siguiente destino y su id a la ruta óptima\n",
    "        ruta_optima.append((siguiente_destino_idx, siguiente_destino_id))\n",
    "        \n",
    "    # Revertir el orden de los elementos en la lista ruta_optima\n",
    "    ruta_optima = ruta_optima[::-1]\n",
    "        \n",
    "    # Crear un DataFrame y añadir el orden y el id de data\n",
    "    orden_ubicaciones = [(ubicaciones[i], id_) for i, id_ in ruta_optima]\n",
    "    # Divide cada tupla en dos columnas separadas\n",
    "    coordenadas=[tupla[0] for tupla in orden_ubicaciones]\n",
    "    ids=[tupla[1] for tupla in orden_ubicaciones]\n",
    "    df_ids = pd.DataFrame(ids, columns=['id'])\n",
    "    orden_df = pd.DataFrame(coordenadas, columns=['lat', 'lon'])\n",
    "    orden_df = pd.concat([orden_df, df_ids], axis=1)\n",
    "    orden_df['orden'] = range(len(orden_df))  \n",
    "    orden_df['label'] = grupo\n",
    "    # Agregar el dataframe con el orden de las ubicaciones a la lista de dataframes\n",
    "    orden_dfs.append(orden_df)\n",
    "\n",
    "if len(orden_dfs)!=0:\n",
    "    #Concatenar los dataframes en un solo dataframe\n",
    "    false_orden_dfs = pd.concat(orden_dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paso 1.1.4 (distintos origenes -> un destino; obtener tiempo de ruta)\n",
    "\n",
    "if 'false_orden_dfs' in globals():\n",
    "    duraciones = []\n",
    "\n",
    "    for data, group in false_orden_dfs.groupby('label'):\n",
    "        durations = []\n",
    "        durations.append(None)\n",
    "        for i in range(len(group)-1):\n",
    "            waypoints = group.iloc[i+1:].values.tolist() + [group.iloc[-1]]\n",
    "            route = gmaps.directions(origin=group.iloc[i],\n",
    "                                    destination=group.iloc[-1],\n",
    "                                    waypoints=waypoints,\n",
    "                                    mode='driving',\n",
    "                                    departure_time= datetime.now())\n",
    "            duration = route[0]['legs'][0]['duration']['value']\n",
    "            durations.append(duration)\n",
    "        # Agregar la lista de las durations de cada recorrido a la lista duraciones\n",
    "        duraciones += durations\n",
    "\n",
    "    #crear dataframe con las duraciones y concatenarlo al dataframe con los ordenes\n",
    "    duraciones=pd.DataFrame(duraciones,columns=['tiempo'])\n",
    "    #duraciones['tiempo']=duraciones['tiempo'].apply(lambda x: round(x/60))\n",
    "    duraciones['tiempo'] = duraciones['tiempo'].apply(lambda x: round(x/60,1) if not pd.isna(x) else x)\n",
    "\n",
    "\n",
    "    false_orden_dfs=pd.concat([false_orden_dfs,duraciones],axis=1)\n",
    "\n",
    "    # rellenar los valores NaN con ceros\n",
    "    false_orden_dfs['tiempo'] = false_orden_dfs['tiempo'].fillna(0)\n",
    "\n",
    "    # agregar una nueva columna con la suma de tiempo por cluster\n",
    "    false_orden_dfs['tiempo_total'] = false_orden_dfs.groupby('label')['tiempo'].transform('sum')\n",
    "    \n",
    "    # Aplicar la función reverse_geocode a cada fila del DataFrame\n",
    "    false_orden_dfs['origen'] = false_orden_dfs.apply(lambda row: reverse_geocode(row['lat'], row['lon']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_df['label'] = np.nan\n",
    "\n",
    "# Agrega una nueva columna con la fecha y hora de recogida combinadas\n",
    "true_df['datetime'] = true_df['fecha'] + ' ' + true_df['hora_recogida']\n",
    "\n",
    "# Agrupa por fecha y hora de recogida combinadas, y por hora de recogida\n",
    "datetime_grouped = true_df.groupby('datetime')\n",
    "\n",
    "# Recorre cada grupo y aplica clustering\n",
    "for name, group in datetime_grouped:\n",
    "    # Calcula la distancia entre cada par de direcciones\n",
    "    X = np.zeros((len(group), len(group)))\n",
    "    for i in range(len(group)):\n",
    "        address1 = group.iloc[i]['destino']\n",
    "        loc1 = geolocate(address1)  # Utilizamos nuestra función personalizada para geolocalizar la dirección\n",
    "        if loc1 is not None:\n",
    "            lat1, lon1 = loc1\n",
    "            point1 = (lat1, lon1)\n",
    "            for j in range(i+1, len(group)):\n",
    "                address2 = group.iloc[j]['destino']\n",
    "                loc2 = geolocate(address2)  # Utilizamos nuestra función personalizada para geolocalizar la dirección\n",
    "                if loc2 is not None:\n",
    "                    lat2, lon2 = loc2\n",
    "                    point2 = (lat2, lon2)\n",
    "                    X[i, j] = great_circle(point1, point2).m\n",
    "                    X[j, i] = great_circle(point1, point2).m\n",
    "    \n",
    "        # Crea una matriz con las distancias\n",
    "        kmeans_1 = KMeans(n_clusters=1)\n",
    "        kmeans_1.fit(X)\n",
    "        group['label'] = kmeans_1.labels_\n",
    "        labels_1 = np.zeros(len(group))\n",
    "        \n",
    "        # Asigna un número de cluster único a cada grupo\n",
    "        last_label_1 = true_df['label'].max()\n",
    "        if np.isnan(last_label_1):\n",
    "            cluster_label_1 = 1\n",
    "        else:\n",
    "            cluster_label_1 = last_label_1 + 1\n",
    "        for i in range(len(group)):\n",
    "            if labels_1[i] == 0:\n",
    "                labels_1[i] = cluster_label_1\n",
    "                for j in range(i+1, len(group)):\n",
    "                    if labels_1[j] == 0 and np.sum(labels_1 == cluster_label_1) < 8 and X[i, j] > 0:\n",
    "                        labels_1[j] = cluster_label_1\n",
    "                if np.sum(labels_1 == cluster_label_1) > 0:\n",
    "                    cluster_label_1 += 1\n",
    "    \n",
    "    # Asigna las etiquetas de los clusters al dataframe original\n",
    "    group['label'] = labels_1\n",
    "    true_df.loc[group.index, \"label\"] = group[\"label\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paso 1.2.2 (un origen-> distintos destinos ; agregar origen en la ruta)\n",
    "\n",
    "true_df=true_df[['hora_recogida','address','destino','label','id','nombre_pasajero','mail','phone','datetime_1']] #######\n",
    "true_df=true_df.sort_values(by=['label'])\n",
    "\n",
    "grouped= true_df.groupby(['address','label'])\n",
    "\n",
    "for data,group in grouped:\n",
    "    group.reset_index(drop=True,inplace=True)\n",
    "    nueva_fila = {'hora_recogida': group['hora_recogida'][0], 'address': data[0], 'destino': data[0],'label': data[1]}\n",
    "    true_df = true_df.append(nueva_fila, ignore_index=True)\n",
    "    \n",
    "true_df['aux']= true_df['address']==true_df['destino']\n",
    "\n",
    "true_df=true_df.sort_values(by=['label']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paso 1.2.3 (un origen-> distintos destinos ; calcular ruta más eficiente)\n",
    "\n",
    "clave_api='AIzaSyAvTzCycvOetN-NA51GNqxb80d-Ma-0Azg'\n",
    "\n",
    "# Agregar columnas para latitud y longitud\n",
    "true_df['latitud'] = None\n",
    "true_df['longitud'] = None\n",
    "\n",
    "# Iterar por cada dirección y obtener las coordenadas\n",
    "for index, row in true_df.iterrows():\n",
    "    direccion = row['destino']\n",
    "    resultado = gmaps.geocode(direccion)\n",
    "    latitud = resultado[0]['geometry']['location']['lat']\n",
    "    longitud = resultado[0]['geometry']['location']['lng']\n",
    "    true_df.at[index, 'latitud'] = latitud\n",
    "    true_df.at[index, 'longitud'] = longitud\n",
    "    \n",
    "\n",
    "# Crear una lista vacía para almacenar los dataframes con los órdenes de las ubicaciones\n",
    "orden_dfs = []\n",
    "\n",
    "\n",
    "# Agrupar el dataframe por cluster\n",
    "grupos = true_df.groupby('label')\n",
    "\n",
    "# Iterar por cada cluster\n",
    "\n",
    "for grupo, data in grupos:\n",
    "    gmaps = googlemaps.Client(key='AIzaSyBDGJCBvgh1BsTLpiDf1UVAwU9e9b_lrd8')\n",
    "    data = data.reset_index(drop=True)\n",
    "    ubicaciones = list(zip(data['latitud'], data['longitud']))\n",
    "    \n",
    "    # Definir el primer destino como el origen\n",
    "    primer_destino_idx = data.loc[data['aux'] == True].iloc[-1].name\n",
    "    primer_destino_id = data.loc[data['aux'] == True, 'id'].iloc[-1]\n",
    "    ruta_optima = [(primer_destino_idx, primer_destino_id)]\n",
    "\n",
    "    # Iterar hasta que se hayan agregado todos los destinos a la ruta\n",
    "    while len(ruta_optima) < len(data):\n",
    "        # Obtener la ubicación actual y las ubicaciones restantes\n",
    "        ubicacion_actual_idx, ubicacion_actual_id = ruta_optima[-1]\n",
    "        ubicacion_actual = ubicaciones[ubicacion_actual_idx]\n",
    "        ubicaciones_restantes = [(i, id_) for i, id_ in zip(range(len(ubicaciones)), data['id']) if i not in [idx for idx, _ in ruta_optima]]\n",
    "        # Calcular la distancia de la ubicación actual a cada ubicación restante\n",
    "        distances = gmaps.distance_matrix(ubicacion_actual, [ubicaciones[i] for i, _ in ubicaciones_restantes], mode='driving')\n",
    "        distances = distances['rows'][0]['elements']\n",
    "        # Ordenar las ubicaciones restantes por distancia al siguiente destino\n",
    "        sorted_indices = sorted(range(len(distances)), key=lambda k: distances[k]['distance']['value'])\n",
    "        \n",
    "        # Elegir el siguiente destino como la ubicación más cercana\n",
    "        siguiente_destino_idx, siguiente_destino_id = ubicaciones_restantes[sorted_indices[0]]\n",
    "        # Agregar el siguiente destino y su id a la ruta óptima\n",
    "        ruta_optima.append((siguiente_destino_idx, siguiente_destino_id))\n",
    "        \n",
    "    # Crear un DataFrame y añadir el orden y el id de data\n",
    "    orden_ubicaciones = [(ubicaciones[i], id_) for i, id_ in ruta_optima]\n",
    "    # Divide cada tupla en dos columnas separadas\n",
    "    coordenadas=[tupla[0] for tupla in orden_ubicaciones]\n",
    "    ids=[tupla[1] for tupla in orden_ubicaciones]\n",
    "    df_ids = pd.DataFrame(ids, columns=['id'])\n",
    "    orden_df = pd.DataFrame(coordenadas, columns=['lat', 'lon'])\n",
    "    orden_df = pd.concat([orden_df, df_ids], axis=1)\n",
    "    orden_df['orden'] = range(len(orden_df))  \n",
    "    orden_df['label'] = grupo\n",
    "    \n",
    "    # Agregar el dataframe con el orden de las ubicaciones a la lista de dataframes\n",
    "    orden_dfs.append(orden_df)\n",
    "\n",
    "if len(orden_dfs)!=0:\n",
    "    # Concatenar los dataframes en un solo dataframe\n",
    "    true_orden_dfs = pd.concat(orden_dfs, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paso 1.2.4 (un origen-> distintos destinos ; obtener duración de ruta)\n",
    "\n",
    "if 'true_orden_dfs' in globals():\n",
    "    duraciones = []\n",
    "\n",
    "    for data, group in true_orden_dfs.groupby('label'):\n",
    "        durations = []\n",
    "        durations.append(None)\n",
    "        for i in range(len(group)-1):\n",
    "            route = gmaps.directions(origin=group.iloc[i],\n",
    "                                    destination=group.iloc[i+1],\n",
    "                                    waypoints=group.iloc[i+1:-1].values.tolist(),\n",
    "                                    mode='driving',\n",
    "                                    departure_time=datetime.now())                   ########### asignar hora de partida, según el grupo\n",
    "            duration = route[0]['legs'][0]['duration']['value']\n",
    "            durations.append(duration)\n",
    "        # Agregar la lista de las durations de cada recorrido a la lista duraciones\n",
    "        duraciones += durations\n",
    "\n",
    "    #crear dataframe con las duraciones y concatenarlo al dataframe con los ordenes\n",
    "    duraciones=pd.DataFrame(duraciones,columns=['tiempo'])\n",
    "    duraciones['tiempo']=duraciones['tiempo'].apply(lambda x: round(x/60,1))\n",
    "\n",
    "    true_orden_dfs=pd.concat([true_orden_dfs,duraciones],axis=1)\n",
    "\n",
    "    # rellenar los valores NaN con ceros\n",
    "    true_orden_dfs['tiempo'] = true_orden_dfs['tiempo'].fillna(0)\n",
    "\n",
    "    # agregar una nueva columna con la suma de tiempo por cluster\n",
    "    true_orden_dfs['tiempo_total'] = true_orden_dfs.groupby('label')['tiempo'].transform('sum')\n",
    "    \n",
    "    # Aplicar la función reverse_geocode a cada fila del DataFrame\n",
    "    true_orden_dfs['destino'] = true_orden_dfs.apply(lambda row: reverse_geocode(row['lat'], row['lon']), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paso 2 concatenar ambos dfs (true_orden_dfs y false_orden_dfs)\n",
    "\n",
    "\n",
    "\n",
    "unordered_df=pd.concat([false_df,true_df])\n",
    "\n",
    "if 'false_orden_dfs' in globals():\n",
    "    false_orden_dfs.dropna(subset='id',inplace=True)\n",
    "    test_false=pd.merge(false_orden_dfs,unordered_df,on='id',how='left',suffixes=('_x', '_y'),validate='one_to_many')\n",
    "\n",
    "if 'true_orden_dfs' in globals():\n",
    "    true_orden_dfs.dropna(subset='id',inplace=True)\n",
    "    test_true=pd.merge(true_orden_dfs,unordered_df,on='id',how='left',suffixes=('_x', '_y'),validate='one_to_many')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'test_false' in globals():\n",
    "    test_false['address']=test_false['origen']\n",
    "    test_false.drop(columns=['origen'],inplace=True)\n",
    "    test_false.drop_duplicates(subset=['label_x','address','tiempo','destino'],inplace=True,keep='last')\n",
    "\n",
    "if 'test_true' in globals() and 'test_false' in globals():\n",
    "    test_true['destino']=test_true['destino_x']\n",
    "    test_true.drop(columns=['destino_x'],inplace=True)\n",
    "    test_true['label_x']=test_true['label_x']+len(test_false['label_x'].unique())\n",
    "    test_true.drop_duplicates(subset=['label_x','address','tiempo','destino'],inplace=True,keep='last')\n",
    "    test_true['aux']= test_true['address']==test_true['destino']\n",
    "    test_true=test_true[test_true['aux']!=True]\n",
    "    test_true=test_true[['label_x','orden','hora_recogida','address','destino','tiempo','id','nombre_pasajero','mail','phone','datetime_1','tiempo_total']]\n",
    "    \n",
    "elif 'test_true' in globals() and 'test_false' not in globals():\n",
    "    test_true['destino']=test_true['destino_x']\n",
    "    test_true.drop(columns=['destino_x'],inplace=True)\n",
    "    test_true.drop_duplicates(subset=['label_x','address','tiempo','destino'],inplace=True,keep='last')\n",
    "    test_true['aux']= test_true['address']==test_true['destino']\n",
    "    test_true=test_true[test_true['aux']!=True]\n",
    "    test_true=test_true[['label_x','orden','hora_recogida','address','destino','tiempo','id','nombre_pasajero','mail','phone','datetime_1','tiempo_total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'test_true' in globals() and 'test_false' not in globals():\n",
    "    df = test_true\n",
    "elif 'test_true' not in globals() and 'test_false' in globals():\n",
    "    df = test_false\n",
    "elif 'test_true' in globals() and 'test_false' in globals():\n",
    "    df=pd.concat([test_false,test_true])\n",
    "    df=df[['label_x','mail','nombre_pasajero','address','destino','datetime_1','hora_recogida','phone','tiempo','orden','tiempo_total']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_x</th>\n",
       "      <th>orden</th>\n",
       "      <th>hora_recogida</th>\n",
       "      <th>address</th>\n",
       "      <th>destino</th>\n",
       "      <th>tiempo</th>\n",
       "      <th>id</th>\n",
       "      <th>nombre_pasajero</th>\n",
       "      <th>mail</th>\n",
       "      <th>phone</th>\n",
       "      <th>datetime_1</th>\n",
       "      <th>tiempo_total</th>\n",
       "      <th>Ruta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22:00</td>\n",
       "      <td>Av. Andrés Bello 2711, Las Condes, Región Metr...</td>\n",
       "      <td>Sta. Elena de Huechuraba 1398, Huechuraba, Reg...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Test Olivares 1</td>\n",
       "      <td>test@test.cl 1</td>\n",
       "      <td>999999999</td>\n",
       "      <td>2023-07-07 22:00:00</td>\n",
       "      <td>151.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>22:00</td>\n",
       "      <td>Av. Andrés Bello 2711, Las Condes, Región Metr...</td>\n",
       "      <td>Río Palena 9670, Pudahuel, Cerro Navia, Región...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Test Olivares 3</td>\n",
       "      <td>test@test.cl 3</td>\n",
       "      <td>999999999</td>\n",
       "      <td>2023-07-07 22:00:00</td>\n",
       "      <td>151.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>22:00</td>\n",
       "      <td>Av. Andrés Bello 2711, Las Condes, Región Metr...</td>\n",
       "      <td>Primera Transversal 1940, Maipú, Región Metrop...</td>\n",
       "      <td>16.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Test Olivares 2</td>\n",
       "      <td>test@test.cl 2</td>\n",
       "      <td>999999999</td>\n",
       "      <td>2023-07-07 22:00:00</td>\n",
       "      <td>151.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>22:00</td>\n",
       "      <td>Av. Andrés Bello 2711, Las Condes, Región Metr...</td>\n",
       "      <td>Av. Eduardo Frei Montalva 1531, Lo Espejo, Reg...</td>\n",
       "      <td>15.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Test Olivares 4</td>\n",
       "      <td>test@test.cl 4</td>\n",
       "      <td>999999999</td>\n",
       "      <td>2023-07-07 22:00:00</td>\n",
       "      <td>151.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>22:00</td>\n",
       "      <td>Av. Andrés Bello 2711, Las Condes, Región Metr...</td>\n",
       "      <td>Av. Concha y Toro 1820, 8150215 Puente Alto, R...</td>\n",
       "      <td>20.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Test Olivares 5</td>\n",
       "      <td>test@test.cl 5</td>\n",
       "      <td>999999999</td>\n",
       "      <td>2023-07-07 22:00:00</td>\n",
       "      <td>151.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>22:00</td>\n",
       "      <td>Av. Andrés Bello 2711, Las Condes, Región Metr...</td>\n",
       "      <td>Av. Concha y Toro 2548, Pirque, Región Metropo...</td>\n",
       "      <td>14.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Test Olivares 7</td>\n",
       "      <td>test@test.cl 7</td>\n",
       "      <td>999999999</td>\n",
       "      <td>2023-07-07 22:00:00</td>\n",
       "      <td>151.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>22:00</td>\n",
       "      <td>Av. Andrés Bello 2711, Las Condes, Región Metr...</td>\n",
       "      <td>Av. 21 de Mayo n° 875, Talagante, Región Metro...</td>\n",
       "      <td>54.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Test Olivares 6</td>\n",
       "      <td>test@test.cl 6</td>\n",
       "      <td>999999999</td>\n",
       "      <td>2023-07-07 22:00:00</td>\n",
       "      <td>151.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label_x  orden hora_recogida  \\\n",
       "0      1.0      1         22:00   \n",
       "1      1.0      2         22:00   \n",
       "2      1.0      3         22:00   \n",
       "3      1.0      4         22:00   \n",
       "4      1.0      5         22:00   \n",
       "5      1.0      6         22:00   \n",
       "6      1.0      7         22:00   \n",
       "\n",
       "                                             address  \\\n",
       "0  Av. Andrés Bello 2711, Las Condes, Región Metr...   \n",
       "1  Av. Andrés Bello 2711, Las Condes, Región Metr...   \n",
       "2  Av. Andrés Bello 2711, Las Condes, Región Metr...   \n",
       "3  Av. Andrés Bello 2711, Las Condes, Región Metr...   \n",
       "4  Av. Andrés Bello 2711, Las Condes, Región Metr...   \n",
       "5  Av. Andrés Bello 2711, Las Condes, Región Metr...   \n",
       "6  Av. Andrés Bello 2711, Las Condes, Región Metr...   \n",
       "\n",
       "                                             destino  tiempo   id  \\\n",
       "0  Sta. Elena de Huechuraba 1398, Huechuraba, Reg...    13.0  0.0   \n",
       "1  Río Palena 9670, Pudahuel, Cerro Navia, Región...    16.0  2.0   \n",
       "2  Primera Transversal 1940, Maipú, Región Metrop...    16.8  1.0   \n",
       "3  Av. Eduardo Frei Montalva 1531, Lo Espejo, Reg...    15.7  3.0   \n",
       "4  Av. Concha y Toro 1820, 8150215 Puente Alto, R...    20.7  4.0   \n",
       "5  Av. Concha y Toro 2548, Pirque, Región Metropo...    14.8  6.0   \n",
       "6  Av. 21 de Mayo n° 875, Talagante, Región Metro...    54.1  5.0   \n",
       "\n",
       "   nombre_pasajero            mail      phone          datetime_1  \\\n",
       "0  Test Olivares 1  test@test.cl 1  999999999 2023-07-07 22:00:00   \n",
       "1  Test Olivares 3  test@test.cl 3  999999999 2023-07-07 22:00:00   \n",
       "2  Test Olivares 2  test@test.cl 2  999999999 2023-07-07 22:00:00   \n",
       "3  Test Olivares 4  test@test.cl 4  999999999 2023-07-07 22:00:00   \n",
       "4  Test Olivares 5  test@test.cl 5  999999999 2023-07-07 22:00:00   \n",
       "5  Test Olivares 7  test@test.cl 7  999999999 2023-07-07 22:00:00   \n",
       "6  Test Olivares 6  test@test.cl 6  999999999 2023-07-07 22:00:00   \n",
       "\n",
       "   tiempo_total  Ruta  \n",
       "0         151.1   1.0  \n",
       "1         151.1   1.0  \n",
       "2         151.1   1.0  \n",
       "3         151.1   1.0  \n",
       "4         151.1   1.0  \n",
       "5         151.1   1.0  \n",
       "6         151.1   1.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['aux']= df['address']==df['destino']\n",
    "df['Ruta']=df['label_x']\n",
    "df=df[df['aux']!=True]\n",
    "df.drop(columns=['aux'],inplace=True)\n",
    "df['phone'] = df['phone'].apply(lambda x: round(x))\n",
    "\n",
    "df.sort_values(by=['datetime_1','label_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traer los\n",
    "#same_origin.sort_values(by=['address','destino'])\n",
    "\n",
    "#same_origin['cluster'] = same_origin.groupby(['address','destino']).ngroup()+1\n",
    "\n",
    "#same_origin.sort_values(by=['cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_excel('reservas-adt-3.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final.sort_values(by=['label','orden']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución del segundo bloque de código: 4.51 segundos\n"
     ]
    }
   ],
   "source": [
    "\n",
    "end_time = time.time()\n",
    "print(\"Tiempo de ejecución del segundo bloque de código: %.2f segundos\" % (end_time - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7224ece411c9dd322214926371e93f477dfdf89a3f2a86d87350b103306a521f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
