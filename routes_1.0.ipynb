{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización de rutas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importar librerias necesarias\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from geopy.distance import great_circle\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import linkage ,fcluster\n",
    "import googlemaps\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "max_pasajeros=4\n",
    "max_minutos=50\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\martin.olivares\\Desktop\\projects\\best-route\\data\\adt_13_03.csv')\n",
    "\n",
    "#data=pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de valores erroneos:\n",
      "address             0\n",
      "hora_recogida       0\n",
      "destino             0\n",
      "nombre_pasajero     0\n",
      "mail                0\n",
      "phone               0\n",
      "fecha               0\n",
      "num_empty_cells     0\n",
      "nulls              82\n",
      "datetime_1          0\n",
      "dtype: int64\n",
      "-----------------------------------\n",
      "Lista errores:\n"
     ]
    }
   ],
   "source": [
    "#limpiar data\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df['address']=data['Direccion de inicio']\n",
    "df['hora_recogida']=data['Hora de recogida']\n",
    "df['destino']=data['Dirección destino']\n",
    "df['nombre_pasajero']=data['Nombre de pasajero']                     #nueva\n",
    "df['mail']=data['Correo pasajero']                                  #nueva\n",
    "df['phone']=data['Telefono de contacto']#.apply(lambda x: round(x))\n",
    "df['fecha']=data['fecha']\n",
    "\n",
    "df[\"num_empty_cells\"] = df.isna().sum(axis=1)\n",
    "df[\"nulls\"]=df['num_empty_cells']/max(df['num_empty_cells'])\n",
    "\n",
    "\n",
    "# Función para crear objetos datetime\n",
    "def crear_datetime(row):\n",
    "    fecha_str = row['fecha']\n",
    "    hora_str = row['hora_recogida']\n",
    "    # Convertir la cadena de texto de hora a un objeto time\n",
    "    hora = datetime.strptime(hora_str, '%H:%M').time()\n",
    "    # Crear un objeto datetime a partir de la fecha y hora\n",
    "    fecha = datetime.strptime(fecha_str, '%Y-%m-%d').date()\n",
    "    fecha_y_hora = datetime.combine(fecha, hora)\n",
    "    return fecha_y_hora\n",
    "\n",
    "# Agregar una nueva columna datetime y conservar las columnas existentes\n",
    "df = df.assign(datetime_1=df.apply(crear_datetime, axis=1))\n",
    "\n",
    "\n",
    "\n",
    "print('Numero de valores erroneos:')\n",
    "print(df.isna().sum())\n",
    "print('-----------------------------------')\n",
    "print('Lista errores:')\n",
    "#df[df.isna().any(axis=1)]\n",
    "\n",
    "df = df.drop(df[df['nulls']==1].index)\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "\n",
    "df.drop(columns=['nulls','num_empty_cells'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corregir typos\n",
    "# Definir un diccionario con las abreviaturas de calles y sus correspondientes formas completas\n",
    "street_abbreviations = {\n",
    "    \"cl\": \"calle\",\n",
    "    \"av\": \"avenida\",\n",
    "    \"pj\": \"pasaje\",\n",
    "    \"cam\": \"camino\",\n",
    "    \"nte\": \"norte\",\n",
    "    \"hermnos\":'hnos',\n",
    "    'hmnos':'hermanos',\n",
    "    'tte':'teniente',\n",
    "    'concon':'con con'\n",
    "    }\n",
    "\n",
    "\n",
    "# Definir una función que corrija las abreviaturas de calles en una dirección\n",
    "def correct_typos(address):\n",
    "    for abbreviation, full_form in street_abbreviations.items():\n",
    "        address = re.sub(r'\\b{}\\b'.format(abbreviation), full_form, address)\n",
    "    return address\n",
    "\n",
    "# Aplicar la función a cada dirección del DataFrame\n",
    "df[\"address\"] = df[\"address\"].str.lower().apply(correct_typos)\n",
    "df['destino'] = df[\"destino\"].str.lower().apply(correct_typos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crear funciones de caché y de limpieza de direcciones\n",
    "\n",
    "gmaps = googlemaps.Client(key='AIzaSyBDGJCBvgh1BsTLpiDf1UVAwU9e9b_lrd8')\n",
    "\n",
    "\n",
    "################################################################# corregir typos\n",
    "\n",
    "googlemaps_cache = 'googlemaps_cache.pkl'\n",
    "\n",
    "def load_cache():\n",
    "    # Cargar la caché desde el archivo si existe\n",
    "    if os.path.exists(googlemaps_cache):\n",
    "        with open(googlemaps_cache, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "def save_cache(cache):\n",
    "    # Guardar la caché en el archivo\n",
    "    with open(googlemaps_cache, 'wb') as f:\n",
    "        pickle.dump(cache, f)\n",
    "\n",
    "def correct_address(direccion):\n",
    "    # Cargar la caché desde el archivo\n",
    "    cache = load_cache()\n",
    "    # Verificar si el resultado de la dirección ya está en la caché\n",
    "    if direccion in cache:\n",
    "        return cache[direccion]\n",
    "    # Si el resultado de la dirección no está en la caché, realizar una solicitud a la API de Google Maps\n",
    "    geocode_result = gmaps.geocode(direccion) \n",
    "    if len(geocode_result) > 0:\n",
    "        formatted_address = geocode_result[0]['formatted_address']\n",
    "        # Agregar el resultado a la caché para futuras solicitudes\n",
    "        cache[direccion] = formatted_address\n",
    "        save_cache(cache)\n",
    "        return formatted_address\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "    \n",
    "################################################################# reverse geocoding\n",
    "\n",
    "googlemaps_reverse_cache = 'googlemaps_reverse_cache.pkl'\n",
    "\n",
    "def load_reverse_cache():\n",
    "    # Cargar la caché desde el archivo si existe\n",
    "    if os.path.exists(googlemaps_reverse_cache):\n",
    "        with open(googlemaps_reverse_cache, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "def save_reverse_cache(cache):\n",
    "    # Guardar la caché en el archivo\n",
    "    with open(googlemaps_reverse_cache, 'wb') as f:\n",
    "        pickle.dump(cache, f)\n",
    "\n",
    "def reverse_geocode(lat, lon):\n",
    "    # Cargar la caché desde el archivo\n",
    "    cache = load_reverse_cache()\n",
    "    # Verificar si el resultado de la dirección ya está en la caché\n",
    "    if (lat, lon) in cache:\n",
    "        return cache[(lat, lon)]\n",
    "    # Si el resultado de la dirección no está en la caché, realizar una solicitud a la API de Google Maps para hacer reverse geocoding\n",
    "    reverse_geocode_result = gmaps.reverse_geocode((lat, lon))      \n",
    "    if len(reverse_geocode_result) > 0:\n",
    "        formatted_address = reverse_geocode_result[0]['formatted_address']\n",
    "        # Agregar el resultado a la caché para futuras solicitudes\n",
    "        cache[(lat, lon)] = formatted_address\n",
    "        save_reverse_cache(cache)\n",
    "        return formatted_address\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "############################################################## georeferenciación \n",
    "\n",
    "\n",
    "\n",
    "# Establecer el nombre del archivo de caché\n",
    "googlemaps_geocode_cache = 'googlemaps_geocode_cache.pkl'\n",
    "\n",
    "def load_geocode_cache():\n",
    "    # Cargar la caché desde el archivo si existe\n",
    "    if os.path.exists(googlemaps_geocode_cache):\n",
    "        with open(googlemaps_geocode_cache, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "def save_geocode_cache(cache):\n",
    "    # Guardar la caché en el archivo\n",
    "    with open(googlemaps_geocode_cache, 'wb') as f:\n",
    "        pickle.dump(cache, f)\n",
    "\n",
    "def geocode(direccion):\n",
    "    # Cargar la caché desde el archivo\n",
    "    cache = load_geocode_cache()\n",
    "    # Verificar si el resultado de la geocodificación ya está en la caché\n",
    "    if direccion in cache:\n",
    "        return cache[direccion]\n",
    "    # Si el resultado de la geocodificación no está en la caché, realizar una solicitud a la API de Google Maps para hacer geocodificación\n",
    "    geocode_result = gmaps.geocode(direccion)      \n",
    "    if len(geocode_result) > 0:\n",
    "        lat = geocode_result[0]['geometry']['location']['lat']\n",
    "        lng = geocode_result[0]['geometry']['location']['lng']\n",
    "        # Agregar el resultado a la caché para futuras solicitudes\n",
    "        cache[direccion] = (lat, lng)\n",
    "        save_geocode_cache(cache)\n",
    "        return (lat, lng)\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "    \n",
    "############################################################## distance matrix\n",
    "\n",
    "# Establecer el nombre del archivo de caché\n",
    "googlemaps_distance_matrix_cache = 'googlemaps_distance_matrix_cache.pkl'\n",
    "\n",
    "\n",
    "def load_distance_matrix_cache():\n",
    "    # Cargar la caché desde el archivo si existe\n",
    "    if os.path.exists(googlemaps_distance_matrix_cache):\n",
    "        with open(googlemaps_distance_matrix_cache, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "def save_distance_matrix_cache(cache):\n",
    "    # Guardar la caché en el archivo\n",
    "    with open(googlemaps_distance_matrix_cache, 'wb') as f:\n",
    "        pickle.dump(cache, f)\n",
    "\n",
    "def distance_matrix(origin, destinations, mode='driving', departure_time=datetime.now()):    \n",
    "    \n",
    "    # Convertir la lista de destinos en una cadena separada por comas\n",
    "    #destinations_str = ','.join(destinations)\n",
    "    # Crear una clave única de caché para esta solicitud de matriz de distancia\n",
    "    cache_key = f\"{origin}_{destinations}_{mode}\"\n",
    "    \n",
    "    # Cargar la caché desde el archivo\n",
    "    cache = load_distance_matrix_cache()\n",
    "    \n",
    "    # Verificar si el resultado de la matriz de distancia ya está en la caché\n",
    "    if cache_key in cache:\n",
    "        return cache[cache_key]\n",
    "    \n",
    "    # Si el resultado de la matriz de distancia no está en la caché, realizar una solicitud a la API de Google Maps para obtener la matriz de distancia\n",
    "    result = gmaps.distance_matrix(\n",
    "        origin,\n",
    "        destinations,\n",
    "        mode=mode)\n",
    "    \n",
    "    if result['status'] == 'OK':\n",
    "        # Agregar el resultado a la caché para futuras solicitudes\n",
    "        cache[cache_key] = result\n",
    "        save_distance_matrix_cache(cache)\n",
    "        return result\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "############################################################## directions\n",
    "\n",
    "\n",
    "# Establecer el nombre del archivo de caché\n",
    "googlemaps_directions_cache = 'googlemaps_directions_cache.pkl'\n",
    "\n",
    "def load_directions_cache():\n",
    "    # Cargar la caché desde el archivo si existe\n",
    "    if os.path.exists(googlemaps_directions_cache):\n",
    "        with open(googlemaps_directions_cache, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "def save_directions_cache(cache):\n",
    "    # Guardar la caché en el archivo\n",
    "    with open(googlemaps_directions_cache, 'wb') as f:\n",
    "        pickle.dump(cache, f)\n",
    "\n",
    "def directions(origin, destination, waypoints, mode='driving',departure_time=datetime.now()):    \n",
    "    # Crear una clave única de caché para esta solicitud de dirección\n",
    "    cache_key = f\"{origin}_{destination}_{waypoints}_{mode}\"\n",
    "    \n",
    "    # Cargar la caché desde el archivo\n",
    "    cache = load_directions_cache()\n",
    "    \n",
    "    # Verificar si el resultado de la dirección ya está en la caché\n",
    "    if cache_key in cache:\n",
    "        return cache[cache_key]\n",
    "    \n",
    "    # Si el resultado de la dirección no está en la caché, realizar una solicitud a la API de Google Maps para obtener la dirección\n",
    "    result = gmaps.directions(\n",
    "        origin=origin,\n",
    "        destination=destination,\n",
    "        waypoints=waypoints,\n",
    "        mode=mode,\n",
    "        departure_time= departure_time)\n",
    "    \n",
    "    if len(result) > 0:\n",
    "        # Agregar el resultado a la caché para futuras solicitudes\n",
    "        cache[cache_key] = result\n",
    "        save_directions_cache(cache)\n",
    "        return result\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corregir direcciones y saber si hay valores erroneos\n",
    "\n",
    "df['address'] = df['address'].apply(correct_address)\n",
    "df['destino'] = df['destino'].apply(correct_address)\n",
    "\n",
    "df['aux'] = ~(df.groupby(['destino', 'datetime_1'])['address'].transform('nunique') > 1)\n",
    "\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separar por muchos origenes un destino, muchos destinos un origen y un origen un destino\n",
    "df.sort_values(by=['datetime_1'],inplace=True)\n",
    "df['id'] = range(len(df))\n",
    "\n",
    "false_df = df[df['aux']==False]\n",
    "true_df = df[df['aux']==True]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#ahora se obtiene cuando existen un origen un destino\n",
    "# 1. marcar con un flag y sacarlas del calculo de distancias\n",
    "# 2. contar la cantidad de personas y definir el producto\n",
    "\n",
    "true_df['aux1'] = true_df.duplicated(subset=['hora_recogida', 'address','destino','fecha'], keep=False)\n",
    "same_origin=true_df[true_df['aux1']==True]\n",
    "true_df=true_df[true_df['aux1']==False]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paso 1.1.1 (distintos origenes -> un destino; crear clusters)\n",
    "\n",
    "false_df['label'] = np.nan\n",
    "\n",
    "# Agrega una nueva columna con la fecha y hora de recogida combinadas\n",
    "false_df['datetime'] = false_df['fecha'] + ' ' + false_df['hora_recogida']\n",
    "\n",
    "# Agrupa por fecha y hora de recogida combinadas, y por hora de recogida\n",
    "datetime_grouped = false_df.groupby('datetime')\n",
    "\n",
    "# Recorre cada grupo y aplica clustering\n",
    "for name, group in datetime_grouped:\n",
    "    # Calcula la distancia entre cada par de direcciones\n",
    "    X = np.zeros((len(group), len(group)))\n",
    "    for i in range(len(group)):\n",
    "        address1 = group.iloc[i]['address']\n",
    "        lat1,lon1 = geocode(address1) # Utilizamos nuestra función personalizada para geolocalizar la dirección\n",
    "        if lat1 is not None:\n",
    "            point1 = (lat1, lon1)\n",
    "            for j in range(i+1, len(group)):\n",
    "                address2 = group.iloc[j]['address']\n",
    "                lat2,lon2 = geocode(address2) # Utilizamos nuestra función personalizada para geolocalizar la dirección\n",
    "                if lat2 is not None:\n",
    "                    point2 = (lat2, lon2)\n",
    "                    X[i, j] = great_circle(point1, point2).m\n",
    "                    X[j, i] = great_circle(point1, point2).m\n",
    "                    \n",
    "    # Crea una matriz con las distancias\n",
    "        kmeans = KMeans(n_clusters=1)\n",
    "        kmeans.fit(X)\n",
    "        group['label'] = kmeans.labels_\n",
    "        labels = np.zeros(len(group))\n",
    "        \n",
    "        # Asigna un número de cluster único a cada grupo\n",
    "        last_label = false_df['label'].max()\n",
    "        if np.isnan(last_label):\n",
    "            cluster_label = 1\n",
    "        else:\n",
    "            cluster_label = last_label + 1\n",
    "        for i in range(len(group)):\n",
    "            if labels[i] == 0:\n",
    "                labels[i] = cluster_label\n",
    "                for j in range(i+1, len(group)):\n",
    "                    if labels[j] == 0 and np.sum(labels == cluster_label) < max_pasajeros and X[i, j] > 0:\n",
    "                        labels[j] = cluster_label\n",
    "                if np.sum(labels == cluster_label) > 0:\n",
    "                    cluster_label += 1\n",
    "    \n",
    "    # Asigna las etiquetas de los clusters al dataframe original\n",
    "    group['label'] = labels\n",
    "    false_df.loc[group.index, \"label\"] = group[\"label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paso 1.1.2 (distintos origenes -> un destino; agregar destino de la ruta)\n",
    "\n",
    "false_df=false_df[['hora_recogida','address','destino','label','id','nombre_pasajero','mail','phone','datetime_1']] #######\n",
    "false_df=false_df.sort_values(by=['label'])\n",
    "\n",
    "grouped= false_df.groupby(['destino','label'])\n",
    "\n",
    "for data,group in grouped:\n",
    "    group.reset_index(drop=True,inplace=True)\n",
    "    nueva_fila = {'hora_recogida': group['hora_recogida'][0], 'address': data[0], 'destino': data[0],'label': data[1]}\n",
    "    false_df = false_df.append(nueva_fila, ignore_index=True)\n",
    "    \n",
    "false_df['aux']= false_df['address']==false_df['destino']\n",
    "\n",
    "false_df=false_df.sort_values(by=['label']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paso 1.1.3 (distintos origenes -> un destino; calcular la ruta más eficiente)\n",
    "\n",
    "# Agregar columnas para latitud y longitud\n",
    "false_df['latitud'] = None\n",
    "false_df['longitud'] = None\n",
    "\n",
    "# Iterar por cada dirección y obtener las coordenadas\n",
    "for index, row in false_df.iterrows():\n",
    "    direccion = row['address']\n",
    "    lat,lng = geocode(direccion) \n",
    "    false_df.at[index, 'latitud'] = lat\n",
    "    false_df.at[index, 'longitud'] = lng\n",
    "    \n",
    "# Crear una lista vacía para almacenar los dataframes con los órdenes de las ubicaciones\n",
    "orden_dfs = []\n",
    "##------------------------------------------------------------------------- bien hasta acá\n",
    "# Agrupar el dataframe por cluster\n",
    "grupos = false_df.groupby('label')\n",
    "\n",
    "# Iterar por cada cluster\n",
    "\n",
    "for grupo, data in grupos:\n",
    "    data = data.reset_index(drop=True)\n",
    "    ubicaciones = list(zip(data['latitud'], data['longitud']))\n",
    "    \n",
    "    # Definir el primer destino como el origen\n",
    "    primer_destino_idx = data.loc[data['aux'] == True].iloc[-1].name\n",
    "    primer_destino_id = data.loc[data['aux'] == True, 'id'].iloc[-1]\n",
    "    ruta_optima = [(primer_destino_idx, primer_destino_id)]\n",
    "    \n",
    "    # Iterar hasta que se hayan agregado todos los destinos a la ruta\n",
    "    while len(ruta_optima) < len(data):\n",
    "        # Obtener la ubicación actual y las ubicaciones restantes\n",
    "        ubicacion_actual_idx, ubicacion_actual_id = ruta_optima[-1]\n",
    "        ubicacion_actual = ubicaciones[ubicacion_actual_idx]\n",
    "        ubicaciones_restantes = [(i, id_) for i, id_ in zip(range(len(ubicaciones)), data['id']) if i not in [idx for idx, _ in ruta_optima]]\n",
    "        # Calcular la distancia de la ubicación actual a cada ubicación restante\n",
    "        #************************************************************************************************************************************************\n",
    "        distances = distance_matrix(origin=ubicacion_actual,destinations= [ubicaciones[i] for i, _ in ubicaciones_restantes])\n",
    "        distances = distances['rows'][0]['elements']\n",
    "        # Ordenar las ubicaciones restantes por distancia al siguiente destino\n",
    "        sorted_indices = sorted(range(len(distances)), key=lambda k: distances[k]['distance']['value'])\n",
    "        # Elegir el siguiente destino como la ubicación más cercana\n",
    "        siguiente_destino_idx, siguiente_destino_id = ubicaciones_restantes[sorted_indices[0]]\n",
    "        # Agregar el siguiente destino y su id a la ruta óptima\n",
    "        ruta_optima.append((siguiente_destino_idx, siguiente_destino_id))\n",
    "        \n",
    "    # Revertir el orden de los elementos en la lista ruta_optima\n",
    "    ruta_optima = ruta_optima[::-1]\n",
    "        \n",
    "    # Crear un DataFrame y añadir el orden y el id de data\n",
    "    orden_ubicaciones = [(ubicaciones[i], id_) for i, id_ in ruta_optima]\n",
    "    # Divide cada tupla en dos columnas separadas\n",
    "    coordenadas=[tupla[0] for tupla in orden_ubicaciones]\n",
    "    ids=[tupla[1] for tupla in orden_ubicaciones]\n",
    "    df_ids = pd.DataFrame(ids, columns=['id'])\n",
    "    orden_df = pd.DataFrame(coordenadas, columns=['lat', 'lon'])\n",
    "    orden_df = pd.concat([orden_df, df_ids], axis=1)\n",
    "    orden_df['orden'] = range(len(orden_df))  \n",
    "    orden_df['label'] = grupo\n",
    "    # Agregar el dataframe con el orden de las ubicaciones a la lista de dataframes\n",
    "    orden_dfs.append(orden_df)\n",
    "\n",
    "if len(orden_dfs)!=0:\n",
    "    #Concatenar los dataframes en un solo dataframe\n",
    "    false_orden_dfs = pd.concat(orden_dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paso 1.1.4 (distintos origenes -> un destino; obtener tiempo de ruta)\n",
    "\n",
    "if 'false_orden_dfs' in globals():\n",
    "    duraciones = []\n",
    "    last_label = 0  # Variable para llevar la cuenta del último label utilizado\n",
    "    for data, group in false_orden_dfs.groupby('label'):\n",
    "        durations = []\n",
    "        durations.append(None)\n",
    "        for i in range(len(group)-1):\n",
    "            waypoints = group.iloc[i+1:].values.tolist() + [group.iloc[-1]]\n",
    "            route = directions(origin=group.iloc[i], \n",
    "                                    destination=group.iloc[-1],\n",
    "                                    waypoints=waypoints)\n",
    "            duration = route[0]['legs'][0]['duration']['value']\n",
    "            durations.append(duration)\n",
    "        # Agregar la lista de las durations de cada recorrido a la lista duraciones\n",
    "        duraciones += durations\n",
    "        \n",
    "    duraciones=pd.DataFrame(duraciones,columns=['tiempo'])\n",
    "    duraciones['tiempo'] = duraciones['tiempo'].apply(lambda x: round(x/60,1) if not pd.isna(x) else x)\n",
    "    \n",
    "    false_orden_dfs=pd.concat([false_orden_dfs,duraciones],axis=1)\n",
    "    \n",
    "    # rellenar los valores NaN con ceros\n",
    "    false_orden_dfs['tiempo'] = false_orden_dfs['tiempo'].fillna(0)\n",
    "    \n",
    "    # agregar una nueva columna con la suma de tiempo por cluster\n",
    "    false_orden_dfs['tiempo_total'] = false_orden_dfs.groupby('label')['tiempo'].transform('sum')\n",
    "    \n",
    "    \n",
    "    # Aplicar la función reverse_geocode a cada fila del DataFrame\n",
    "    false_orden_dfs['origen'] = false_orden_dfs.apply(lambda row: reverse_geocode(row['lat'], row['lon']), axis=1)\n",
    "    \n",
    "    # Reiniciar los labels desde cero\n",
    "    false_orden_dfs = false_orden_dfs.reset_index(drop=True)\n",
    "    false_orden_dfs['label'] = false_orden_dfs['label'].apply(lambda x: x - false_orden_dfs['label'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_df['label'] = np.nan\n",
    "\n",
    "# Agrega una nueva columna con la fecha y hora de recogida combinadas\n",
    "true_df['datetime'] = true_df['fecha'] + ' ' + true_df['hora_recogida']\n",
    "\n",
    "# Agrupa por fecha y hora de recogida combinadas, y por hora de recogida\n",
    "datetime_grouped = true_df.groupby('datetime')\n",
    "\n",
    "# Recorre cada grupo y aplica clustering\n",
    "for name, group in datetime_grouped:\n",
    "    # Calcula la distancia entre cada par de direcciones\n",
    "    X = np.zeros((len(group), len(group)))\n",
    "    for i in range(len(group)):\n",
    "        address1 = group.iloc[i]['destino']\n",
    "        lat1,lon1 = geocode(address1)  # Utilizamos nuestra función personalizada para geolocalizar la dirección\n",
    "        if lat1 is not None:\n",
    "            point1 = (lat1, lon1)\n",
    "            for j in range(i+1, len(group)):\n",
    "                address2 = group.iloc[j]['destino']\n",
    "                lat2,lon2 = geocode(address2)  # Utilizamos nuestra función personalizada para geolocalizar la dirección\n",
    "                if lat2 is not None:\n",
    "                    point2 = (lat2, lon2)\n",
    "                    X[i, j] = great_circle(point1, point2).m\n",
    "                    X[j, i] = great_circle(point1, point2).m\n",
    "    \n",
    "        # Crea una matriz con las distancias\n",
    "        kmeans_1 = KMeans(n_clusters=1)\n",
    "        kmeans_1.fit(X)\n",
    "        group['label'] = kmeans_1.labels_\n",
    "        labels_1 = np.zeros(len(group))\n",
    "        \n",
    "        # Asigna un número de cluster único a cada grupo\n",
    "        last_label_1 = true_df['label'].max()\n",
    "        if np.isnan(last_label_1):\n",
    "            cluster_label_1 = 1\n",
    "        else:\n",
    "            cluster_label_1 = last_label_1 + 1\n",
    "        for i in range(len(group)):\n",
    "            if labels_1[i] == 0:\n",
    "                labels_1[i] = cluster_label_1\n",
    "                for j in range(i+1, len(group)):\n",
    "                    if labels_1[j] == 0 and np.sum(labels_1 == cluster_label_1) < max_pasajeros and X[i, j] > 0:\n",
    "                        labels_1[j] = cluster_label_1\n",
    "                if np.sum(labels_1 == cluster_label_1) > 0:\n",
    "                    cluster_label_1 += 1\n",
    "    \n",
    "    # Asigna las etiquetas de los clusters al dataframe original\n",
    "    group['label'] = labels_1\n",
    "    true_df.loc[group.index, \"label\"] = group[\"label\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paso 1.2.2 (un origen-> distintos destinos ; agregar origen en la ruta)\n",
    "\n",
    "true_df=true_df[['hora_recogida','address','destino','label','id','nombre_pasajero','mail','phone','datetime_1']] #######\n",
    "true_df=true_df.sort_values(by=['label'])\n",
    "\n",
    "grouped= true_df.groupby(['address','label'])\n",
    "\n",
    "for data,group in grouped:\n",
    "    group.reset_index(drop=True,inplace=True)\n",
    "    nueva_fila = {'hora_recogida': group['hora_recogida'][0], 'address': data[0], 'destino': data[0],'label': data[1]}\n",
    "    true_df = true_df.append(nueva_fila, ignore_index=True)\n",
    "    \n",
    "true_df['aux']= true_df['address']==true_df['destino']\n",
    "\n",
    "true_df=true_df.sort_values(by=['label']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paso 1.2.3 (un origen-> distintos destinos ; calcular ruta más eficiente)\n",
    "\n",
    "clave_api='AIzaSyAvTzCycvOetN-NA51GNqxb80d-Ma-0Azg'\n",
    "\n",
    "# Agregar columnas para latitud y longitud\n",
    "true_df['latitud'] = None\n",
    "true_df['longitud'] = None\n",
    "\n",
    "# Iterar por cada dirección y obtener las coordenadas\n",
    "for index, row in true_df.iterrows():\n",
    "    direccion = row['destino']\n",
    "    lat,lng = geocode(direccion)  #********************************************************************\n",
    "    true_df.at[index, 'latitud'] = lat\n",
    "    true_df.at[index, 'longitud'] = lng\n",
    "    \n",
    "\n",
    "# Crear una lista vacía para almacenar los dataframes con los órdenes de las ubicaciones\n",
    "orden_dfs = []\n",
    "\n",
    "\n",
    "# Agrupar el dataframe por cluster\n",
    "grupos = true_df.groupby('label')\n",
    "\n",
    "# Iterar por cada cluster\n",
    "\n",
    "for grupo, data in grupos:\n",
    "    data = data.reset_index(drop=True)\n",
    "    ubicaciones = list(zip(data['latitud'], data['longitud']))\n",
    "    \n",
    "    # Definir el primer destino como el origen\n",
    "    primer_destino_idx = data.loc[data['aux'] == True].iloc[-1].name\n",
    "    primer_destino_id = data.loc[data['aux'] == True, 'id'].iloc[-1]\n",
    "    ruta_optima = [(primer_destino_idx, primer_destino_id)]\n",
    "\n",
    "    # Iterar hasta que se hayan agregado todos los destinos a la ruta\n",
    "    while len(ruta_optima) < len(data):\n",
    "        # Obtener la ubicación actual y las ubicaciones restantes\n",
    "        ubicacion_actual_idx, ubicacion_actual_id = ruta_optima[-1]\n",
    "        ubicacion_actual = ubicaciones[ubicacion_actual_idx]\n",
    "        ubicaciones_restantes = [(i, id_) for i, id_ in zip(range(len(ubicaciones)), data['id']) if i not in [idx for idx, _ in ruta_optima]]\n",
    "        # Calcular la distancia de la ubicación actual a cada ubicación restante       #********************************************************************\n",
    "        distances = distance_matrix(origin=ubicacion_actual,destinations= [ubicaciones[i] for i, _ in ubicaciones_restantes])\n",
    "        distances = distances['rows'][0]['elements']\n",
    "        # Ordenar las ubicaciones restantes por distancia al siguiente destino\n",
    "        sorted_indices = sorted(range(len(distances)), key=lambda k: distances[k]['distance']['value'])\n",
    "        \n",
    "        # Elegir el siguiente destino como la ubicación más cercana\n",
    "        siguiente_destino_idx, siguiente_destino_id = ubicaciones_restantes[sorted_indices[0]]\n",
    "        # Agregar el siguiente destino y su id a la ruta óptima\n",
    "        ruta_optima.append((siguiente_destino_idx, siguiente_destino_id))\n",
    "        \n",
    "    # Crear un DataFrame y añadir el orden y el id de data\n",
    "    orden_ubicaciones = [(ubicaciones[i], id_) for i, id_ in ruta_optima]\n",
    "    # Divide cada tupla en dos columnas separadas\n",
    "    coordenadas=[tupla[0] for tupla in orden_ubicaciones]\n",
    "    ids=[tupla[1] for tupla in orden_ubicaciones]\n",
    "    df_ids = pd.DataFrame(ids, columns=['id'])\n",
    "    orden_df = pd.DataFrame(coordenadas, columns=['lat', 'lon'])\n",
    "    orden_df = pd.concat([orden_df, df_ids], axis=1)\n",
    "    orden_df['orden'] = range(len(orden_df))  \n",
    "    orden_df['label'] = grupo\n",
    "    \n",
    "    # Agregar el dataframe con el orden de las ubicaciones a la lista de dataframes\n",
    "    orden_dfs.append(orden_df)\n",
    "\n",
    "if len(orden_dfs)!=0:\n",
    "    # Concatenar los dataframes en un solo dataframe\n",
    "    true_orden_dfs = pd.concat(orden_dfs, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paso 1.2.4 (un origen-> distintos destinos ; obtener duración de ruta)\n",
    "\n",
    "if 'true_orden_dfs' in globals():\n",
    "    duraciones = []\n",
    "    last_label = 0  # Variable para llevar la cuenta del último label utilizado\n",
    "    for data, group in true_orden_dfs.groupby('label'):\n",
    "        durations = []\n",
    "        durations.append(None)\n",
    "        for i in range(len(group)-1):\n",
    "            route = directions(origin=group.iloc[i],   #***********************************************************************\n",
    "                                    destination=group.iloc[i+1],\n",
    "                                    waypoints=group.iloc[i+1:-1].values.tolist())                   ########### asignar hora de partida, según el grupo\n",
    "            duration = route[0]['legs'][0]['duration']['value']\n",
    "            durations.append(duration)\n",
    "        # Agregar la lista de las durations de cada recorrido a la lista duraciones\n",
    "        duraciones += durations\n",
    "            \n",
    "    #crear dataframe con las duraciones y concatenarlo al dataframe con los ordenes\n",
    "    duraciones=pd.DataFrame(duraciones,columns=['tiempo'])\n",
    "    duraciones['tiempo']=duraciones['tiempo'].apply(lambda x: round(x/60,1))\n",
    "\n",
    "    true_orden_dfs=pd.concat([true_orden_dfs,duraciones],axis=1)\n",
    "\n",
    "    # rellenar los valores NaN con ceros\n",
    "    true_orden_dfs['tiempo'] = true_orden_dfs['tiempo'].fillna(0)\n",
    "    \n",
    "    # agregar una nueva columna con la suma de tiempo por cluster\n",
    "    true_orden_dfs['tiempo_total'] = true_orden_dfs.groupby('label')['tiempo'].transform('sum')\n",
    "    \n",
    "    #Aplicar la función reverse_geocode a cada fila del DataFrame\n",
    "    true_orden_dfs['destino'] = true_orden_dfs.apply(lambda row: reverse_geocode(row['lat'], row['lon']), axis=1)\n",
    "    # Reiniciar los labels desde cero\n",
    "    true_orden_dfs = true_orden_dfs.reset_index(drop=True)\n",
    "    true_orden_dfs['label'] = true_orden_dfs['label'].apply(lambda x: x - true_orden_dfs['label'].min())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paso 2 concatenar ambos dfs (true_orden_dfs y false_orden_dfs)\n",
    "\n",
    "\n",
    "\n",
    "unordered_df=pd.concat([false_df,true_df])\n",
    "\n",
    "if 'false_orden_dfs' in globals():\n",
    "    false_orden_dfs.dropna(subset='id',inplace=True)\n",
    "    test_false=pd.merge(false_orden_dfs,unordered_df,on='id',how='left',suffixes=('_x', '_y'),validate='one_to_many')\n",
    "\n",
    "if 'true_orden_dfs' in globals():\n",
    "    true_orden_dfs.dropna(subset='id',inplace=True)\n",
    "    test_true=pd.merge(true_orden_dfs,unordered_df,on='id',how='left',suffixes=('_x', '_y'),validate='one_to_many')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'test_false' in globals():\n",
    "    test_false['address']=test_false['origen']\n",
    "    test_false.drop(columns=['origen'],inplace=True)\n",
    "    test_false.drop_duplicates(subset=['label_x','address','tiempo','destino'],inplace=True,keep='last')\n",
    "\n",
    "if 'test_true' in globals() and 'test_false' in globals():\n",
    "    test_true['destino']=test_true['destino_x']\n",
    "    test_true.drop(columns=['destino_x'],inplace=True)\n",
    "    test_true['label_x']=test_true['label_x']+len(test_false['label_x'].unique())+1\n",
    "    test_true.drop_duplicates(subset=['label_x','address','tiempo','destino'],inplace=True,keep='last')\n",
    "    test_true['aux']= test_true['address']==test_true['destino']\n",
    "    test_true=test_true[test_true['aux']!=True]\n",
    "    test_true=test_true[['label_x','orden','hora_recogida','address','destino','tiempo','id','nombre_pasajero','mail','phone','datetime_1','tiempo_total']]\n",
    "    \n",
    "elif 'test_true' in globals() and 'test_false' not in globals():\n",
    "    test_true['destino']=test_true['destino_x']\n",
    "    test_true.drop(columns=['destino_x'],inplace=True)\n",
    "    test_true.drop_duplicates(subset=['label_x','address','tiempo','destino'],inplace=True,keep='last')\n",
    "    test_true['aux']= test_true['address']==test_true['destino']\n",
    "    test_true=test_true[test_true['aux']!=True]\n",
    "    test_true=test_true[['label_x','orden','hora_recogida','address','destino','tiempo','id','nombre_pasajero','mail','phone','datetime_1','tiempo_total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'test_true' in globals() and 'test_false' not in globals():\n",
    "    df = test_true\n",
    "elif 'test_true' not in globals() and 'test_false' in globals():\n",
    "    df = test_false\n",
    "elif 'test_true' in globals() and 'test_false' in globals():\n",
    "    df=pd.concat([test_false,test_true])\n",
    "    df=df[['label_x','mail','nombre_pasajero','address','destino','datetime_1','hora_recogida','phone','tiempo','orden','tiempo_total']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#minor improvements\n",
    "df['aux']= df['address']==df['destino']\n",
    "df['Ruta']=df['label_x']\n",
    "df=df[df['aux']!=True]\n",
    "df.drop(columns=['aux'],inplace=True)\n",
    "df['phone'] = df['phone'].apply(lambda x: round(x))\n",
    "\n",
    "#dividir en 2 cuando es > 90 minutos\n",
    "df=df[['mail','nombre_pasajero','address','destino','datetime_1','hora_recogida','phone','Ruta','orden','tiempo_total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#juntar a los usuarios que tienen mismo origen y mismo destino\n",
    "\n",
    "if len(same_origin)>0:\n",
    "\n",
    "    same_origin['Ruta'] = same_origin.groupby(['address','destino','datetime_1']).ngroup()\n",
    "\n",
    "    max_size = max_pasajeros#--------------------------------------------------------------------------------------------------------\n",
    "    cluster_counts = same_origin['Ruta'].value_counts()\n",
    "    big_clusters = cluster_counts[cluster_counts > max_size].index.tolist()\n",
    "    for cluster in big_clusters:\n",
    "        indices = same_origin[same_origin['Ruta'] == cluster].index\n",
    "        sub_clusters = np.array_split(indices, np.ceil(len(indices)/max_size))\n",
    "        for i, sub_cluster in enumerate(sub_clusters):\n",
    "            same_origin.loc[sub_cluster, 'Ruta'] = f'{cluster}_{i+1}'\n",
    "\n",
    "    same_origin['Ruta']=same_origin.groupby(['Ruta']).ngroup()+df1['Ruta'].max()+1\n",
    "\n",
    "    #obtener duracionde cada viaje\n",
    "\n",
    "    def agregar_tiempo_total(data):\n",
    "        route = directions(origin=data.iloc[0]['address'], \n",
    "                            destination=data.iloc[0]['destino'],\n",
    "                            waypoints=[])\n",
    "        duration = route[0]['legs'][0]['duration']['value']\n",
    "        data['tiempo_total'] = round(duration/60,1)\n",
    "        return data\n",
    "\n",
    "    same_origin = same_origin.groupby('Ruta').apply(agregar_tiempo_total)\n",
    "    same_origin['orden']=1\n",
    "\n",
    "    same_origin=same_origin[['mail','nombre_pasajero','address','destino','datetime_1','hora_recogida','phone','Ruta','orden']]\n",
    "\n",
    "    same_origin.sort_values(by=['Ruta'])\n",
    "    #se concatena con df1\n",
    "    df1=pd.concat([df,same_origin], axis=0)\n",
    "\n",
    "elif len(same_origin)==0:\n",
    "    df1=df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevos_datos = []\n",
    "\n",
    "for ruta, data in df.groupby('Ruta'):\n",
    "    tiempo_total = data['tiempo_total'].mean()\n",
    "    \n",
    "    if tiempo_total > max_minutos:\n",
    "        ruta_1 = str(ruta) + '_1'\n",
    "        ruta_2 = str(ruta) + '_2'\n",
    "        \n",
    "        \n",
    "        data_1 = data.iloc[:len(data) // 2].copy()\n",
    "        data_1['Ruta'] = ruta_1\n",
    "        \n",
    "        data_2 = data.iloc[len(data) // 2:].copy()\n",
    "        data_2['Ruta'] = ruta_2\n",
    "        \n",
    "        nuevos_datos.append(data_1)\n",
    "        nuevos_datos.append(data_2)\n",
    "    else:\n",
    "        nuevos_datos.append(data)\n",
    "        \n",
    "df1 = pd.concat(nuevos_datos, ignore_index=True)\n",
    "\n",
    "df1['ruta'] = df1.groupby(['datetime_1','Ruta']).ngroup()\n",
    "df1['orden_1'] = df1.groupby('ruta').cumcount() + 1\n",
    "df1=df1[['mail','nombre_pasajero','address','destino','datetime_1','hora_recogida','phone','ruta','orden_1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Función para obtener el tiempo de viaje en segundos\n",
    "def obtener_tiempo(row):\n",
    "    now = datetime.now()\n",
    "    waypoints = row['address'][1:-1].split(', ') # Obtener todos los puntos intermedios\n",
    "    directions_result = directions(origin=row['address'][0], destination=row['destino'],  waypoints=waypoints)\n",
    "    tiempo_segundos = directions_result[0]['legs'][0]['duration']['value']\n",
    "    return tiempo_segundos\n",
    "\n",
    "# Agregar una columna nueva al DataFrame con los tiempos de viaje\n",
    "df['tiempo_total'] = df.apply(obtener_tiempo, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df1['aux'] = ~(df1.groupby(['destino', 'datetime_1'])['address'].transform('nunique') > 1)\n",
    "\n",
    "false_df1 = df1[df1['aux']==False]\n",
    "true_df1 = df1[df1['aux']==True]\n",
    "\n",
    "false_df1.sort_values(by=['ruta','orden_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#paso 1. (distintos origenes -> un destino; agregar destino de la ruta)\n",
    "\n",
    "false_df1=false_df1.sort_values(by=['ruta'])\n",
    "\n",
    "grouped= false_df1.groupby(['destino','ruta'])\n",
    "\n",
    "for data,group in grouped:\n",
    "    group.reset_index(drop=True,inplace=True)\n",
    "    nueva_fila = {'datetime_1': group['datetime_1'][0], 'address': data[0], 'destino': data[0],'ruta': data[1]}\n",
    "    false_df1 = false_df1.append(nueva_fila, ignore_index=True)\n",
    "    \n",
    "false_df1['aux']= false_df1['address']==false_df1['destino']\n",
    "\n",
    "false_df1=false_df1.sort_values(by=['ruta']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "duraciones = []\n",
    "last_ruta = 0  # Variable para llevar la cuenta del último ruta utilizado\n",
    "for data, group in false_df1.groupby('ruta'):\n",
    "    durations = []\n",
    "    durations.append(None)\n",
    "    for i in range(len(group)-1):\n",
    "        waypoints = group.iloc[i+1:].values.tolist() + [group.iloc[-1]]\n",
    "        route = directions(origin=group.iloc[i], \n",
    "                                destination=group.iloc[-1],\n",
    "                                waypoints=waypoints)\n",
    "        duration = route[0]['legs'][0]['duration']['value']\n",
    "        durations.append(duration)\n",
    "    # Agregar la lista de las durations de cada recorrido a la lista duraciones\n",
    "    duraciones += durations\n",
    "    \n",
    "duraciones=pd.DataFrame(duraciones,columns=['tiempo'])\n",
    "duraciones['tiempo'] = duraciones['tiempo'].apply(lambda x: round(x/60,1) if not pd.isna(x) else x)\n",
    "\n",
    "false_df1=pd.concat([false_df1,duraciones],axis=1)\n",
    "\n",
    "# rellenar los valores NaN con ceros\n",
    "false_df1['tiempo'] = false_df1['tiempo'].fillna(0)\n",
    "\n",
    "# agregar una nueva columna con la suma de tiempo por cluster\n",
    "false_df1['tiempo_total'] = false_df1.groupby('ruta')['tiempo'].transform('sum')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "false_df1.sort_values(by=['ruta','orden_1'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mail</th>\n",
       "      <th>nombre_pasajero</th>\n",
       "      <th>address</th>\n",
       "      <th>destino</th>\n",
       "      <th>datetime_1</th>\n",
       "      <th>hora_recogida</th>\n",
       "      <th>phone</th>\n",
       "      <th>ruta</th>\n",
       "      <th>orden_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jvandejm@jci.com</td>\n",
       "      <td>VAN-DER MOLEN PEÑALOZA, JOSE MIGUEL</td>\n",
       "      <td>José María Escrivá de Balaguer 720, Concón, Va...</td>\n",
       "      <td>8 Nte. 1168, Viña del Mar, Valparaíso, Chile</td>\n",
       "      <td>2023-03-14 06:00:00</td>\n",
       "      <td>6:00</td>\n",
       "      <td>963402416</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jnavard3@jci.com</td>\n",
       "      <td>NAVARRO TORO, DAYMARY FERNANDA</td>\n",
       "      <td>Séptimo de Línea 17, 2352576 Valparaíso, Chile</td>\n",
       "      <td>8 Nte. 1168, Viña del Mar, Valparaíso, Chile</td>\n",
       "      <td>2023-03-14 06:00:00</td>\n",
       "      <td>6:00</td>\n",
       "      <td>958059542</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jtorr273@jci.com</td>\n",
       "      <td>TORRES TORRES, MARIA PATRICIA</td>\n",
       "      <td>Rio Andalien 1400, Villa Alemana, Valparaíso, ...</td>\n",
       "      <td>8 Nte. 1168, Viña del Mar, Valparaíso, Chile</td>\n",
       "      <td>2023-03-14 06:00:00</td>\n",
       "      <td>6:00</td>\n",
       "      <td>957105246</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jjofres@jci.com</td>\n",
       "      <td>JOFRE QUEZADA, SUSY MAILING</td>\n",
       "      <td>Pje. 0 2930, Viña del Mar, Valparaíso, Chile</td>\n",
       "      <td>8 Nte. 1168, Viña del Mar, Valparaíso, Chile</td>\n",
       "      <td>2023-03-14 06:00:00</td>\n",
       "      <td>6:00</td>\n",
       "      <td>923628209</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jaguirv2@jci.com</td>\n",
       "      <td>AGUIRRE VIVAS, VERONICA YALIMAR</td>\n",
       "      <td>Irma Johnson Molina 2579, Quilpué, Valparaíso,...</td>\n",
       "      <td>8 Nte. 1168, Viña del Mar, Valparaíso, Chile</td>\n",
       "      <td>2023-03-14 06:00:00</td>\n",
       "      <td>6:00</td>\n",
       "      <td>963995462</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>jcuellc1@jci.com</td>\n",
       "      <td>CUELLAR OLEA, CAROLINA ALEXANDRA</td>\n",
       "      <td>Marga Marga 2481, Villa Alemana, Valparaíso, C...</td>\n",
       "      <td>8 Nte. 1168, Viña del Mar, Valparaíso, Chile</td>\n",
       "      <td>2023-03-19 07:00:00</td>\n",
       "      <td>7:00</td>\n",
       "      <td>953348613</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>jdomin54@jci.com</td>\n",
       "      <td>DOMINGUEZ PEGUERO, MIRIAM ESPERANZA</td>\n",
       "      <td>8 Nte. 1168, Viña del Mar, Valparaíso, Chile</td>\n",
       "      <td>Viana 1155, Valparaíso, Viña del Mar, Valparaí...</td>\n",
       "      <td>2023-03-20 22:00:00</td>\n",
       "      <td>22:00</td>\n",
       "      <td>936334969</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>jvalde38@jci.com</td>\n",
       "      <td>VALDEBENITO JIMENEZ, JARLYN NAZARETH</td>\n",
       "      <td>8 Nte. 1168, Viña del Mar, Valparaíso, Chile</td>\n",
       "      <td>Dr. Israel Roizblatt 130, Valparaíso, Chile</td>\n",
       "      <td>2023-03-20 22:00:00</td>\n",
       "      <td>22:00</td>\n",
       "      <td>926050049</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>jcast112@jci.com</td>\n",
       "      <td>CASTILLO MOYANO, MIGUEL NICOLAS</td>\n",
       "      <td>8 Nte. 1168, Viña del Mar, Valparaíso, Chile</td>\n",
       "      <td>Navío San Martín 70, 2352280 Valparaíso, Chile</td>\n",
       "      <td>2023-03-20 22:00:00</td>\n",
       "      <td>22:00</td>\n",
       "      <td>984338154</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>jrolliv@jci.com</td>\n",
       "      <td>ROLLINO VARGAS, VALENTINA GIGLIOLA</td>\n",
       "      <td>8 Nte. 1168, Viña del Mar, Valparaíso, Chile</td>\n",
       "      <td>Camila 109, Valparaíso, Chile</td>\n",
       "      <td>2023-03-20 22:00:00</td>\n",
       "      <td>22:00</td>\n",
       "      <td>979785561</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                mail                       nombre_pasajero  \\\n",
       "0   jvandejm@jci.com   VAN-DER MOLEN PEÑALOZA, JOSE MIGUEL   \n",
       "1   jnavard3@jci.com        NAVARRO TORO, DAYMARY FERNANDA   \n",
       "2   jtorr273@jci.com         TORRES TORRES, MARIA PATRICIA   \n",
       "3    jjofres@jci.com           JOFRE QUEZADA, SUSY MAILING   \n",
       "4   jaguirv2@jci.com       AGUIRRE VIVAS, VERONICA YALIMAR   \n",
       "..               ...                                   ...   \n",
       "77  jcuellc1@jci.com      CUELLAR OLEA, CAROLINA ALEXANDRA   \n",
       "78  jdomin54@jci.com   DOMINGUEZ PEGUERO, MIRIAM ESPERANZA   \n",
       "79  jvalde38@jci.com  VALDEBENITO JIMENEZ, JARLYN NAZARETH   \n",
       "80  jcast112@jci.com       CASTILLO MOYANO, MIGUEL NICOLAS   \n",
       "81   jrolliv@jci.com    ROLLINO VARGAS, VALENTINA GIGLIOLA   \n",
       "\n",
       "                                              address  \\\n",
       "0   José María Escrivá de Balaguer 720, Concón, Va...   \n",
       "1      Séptimo de Línea 17, 2352576 Valparaíso, Chile   \n",
       "2   Rio Andalien 1400, Villa Alemana, Valparaíso, ...   \n",
       "3        Pje. 0 2930, Viña del Mar, Valparaíso, Chile   \n",
       "4   Irma Johnson Molina 2579, Quilpué, Valparaíso,...   \n",
       "..                                                ...   \n",
       "77  Marga Marga 2481, Villa Alemana, Valparaíso, C...   \n",
       "78       8 Nte. 1168, Viña del Mar, Valparaíso, Chile   \n",
       "79       8 Nte. 1168, Viña del Mar, Valparaíso, Chile   \n",
       "80       8 Nte. 1168, Viña del Mar, Valparaíso, Chile   \n",
       "81       8 Nte. 1168, Viña del Mar, Valparaíso, Chile   \n",
       "\n",
       "                                              destino          datetime_1  \\\n",
       "0        8 Nte. 1168, Viña del Mar, Valparaíso, Chile 2023-03-14 06:00:00   \n",
       "1        8 Nte. 1168, Viña del Mar, Valparaíso, Chile 2023-03-14 06:00:00   \n",
       "2        8 Nte. 1168, Viña del Mar, Valparaíso, Chile 2023-03-14 06:00:00   \n",
       "3        8 Nte. 1168, Viña del Mar, Valparaíso, Chile 2023-03-14 06:00:00   \n",
       "4        8 Nte. 1168, Viña del Mar, Valparaíso, Chile 2023-03-14 06:00:00   \n",
       "..                                                ...                 ...   \n",
       "77       8 Nte. 1168, Viña del Mar, Valparaíso, Chile 2023-03-19 07:00:00   \n",
       "78  Viana 1155, Valparaíso, Viña del Mar, Valparaí... 2023-03-20 22:00:00   \n",
       "79        Dr. Israel Roizblatt 130, Valparaíso, Chile 2023-03-20 22:00:00   \n",
       "80     Navío San Martín 70, 2352280 Valparaíso, Chile 2023-03-20 22:00:00   \n",
       "81                      Camila 109, Valparaíso, Chile 2023-03-20 22:00:00   \n",
       "\n",
       "   hora_recogida      phone  ruta  orden_1  \n",
       "0           6:00  963402416     1        1  \n",
       "1           6:00  958059542     1        2  \n",
       "2           6:00  957105246     2        1  \n",
       "3           6:00  923628209     2        2  \n",
       "4           6:00  963995462     0        1  \n",
       "..           ...        ...   ...      ...  \n",
       "77          7:00  953348613    35        1  \n",
       "78         22:00  936334969    39        1  \n",
       "79         22:00  926050049    39        2  \n",
       "80         22:00  984338154    40        1  \n",
       "81         22:00  979785561    40        2  \n",
       "\n",
       "[82 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_excel('reservas-13-03.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución del segundo bloque de código: 19.96 segundos\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "print(\"Tiempo de ejecución del segundo bloque de código: %.2f segundos\" % (end_time - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7224ece411c9dd322214926371e93f477dfdf89a3f2a86d87350b103306a521f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
